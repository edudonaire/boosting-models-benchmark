# Boosting Models Benchmark (LightGBM Ã— XGBoost Ã— CatBoost)

This repository contains a reproducible machine learning benchmark comparing three leading gradient boosting algorithms:

- **LightGBM**
- **XGBoost**
- **CatBoost**

The evaluation includes:
- Standardized feature preprocessing  
- Unified train/validation splits  
- Reproducible pipelines  
- F1-score comparison  
- Training time analysis  
- Model interpretability (optional SHAP workflow)

This project is part of a broader ML governance and evaluation portfolio, demonstrating best practices for model assessment, consistency, and reliability.

---

## ðŸ“‚ Contents
- `boosting_benchmark.ipynb` â€” Main notebook with the entire benchmark  
- `requirements.txt` â€” Dependencies for full reproducibility  
- `README.md` â€” Project documentation  

---

## ðŸ§ª Evaluation Metrics
The benchmark compares models across:
- F1-score  
- Accuracy  
- Training time  
- Inference speed  
- Handling of categorical vs numerical features  

---

## ðŸ§  Why This Matters
Boosting models are widely used in:
- Demand forecasting  
- Churn and classification problems  
- Credit risk scoring  
- Customer segmentation  
- Operational ML pipelines  

This benchmark demonstrates:
- Methodology  
- Reproducibility  
- Model governance  
- Responsible evaluation practices  

---

## ðŸ”— Related Work
- Data Governance Framework (Titanic)  
- SME Digital Maturity Dataset (Synthetic)  
- Kaggle Notebooks by Eduardo Donaire Filho  

---

## ðŸ“œ License
MIT License  

---

## ðŸ‘¤ Author
Eduardo Donaire Filho  
Data & Analytics Coordinator | BI & ML
