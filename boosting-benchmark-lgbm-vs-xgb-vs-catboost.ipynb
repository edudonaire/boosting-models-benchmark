{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Boosting Model Benchmark: LightGBM × XGBoost × CatBoost (F1-Score)\n","metadata":{}},{"cell_type":"markdown","source":"This notebook benchmarks three popular boosting frameworks on the Titanic dataset:\n\n- LightGBM  \n- XGBoost  \n- CatBoost  \n\nWe use:\n- Standardized preprocessing  \n- F1-score as the main evaluation metric  \n- Training time comparison  \n\nThis mirrors real-world model selection under cost, performance, and complexity constraints.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import LabelEncoder\n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostClassifier\n\ndf = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:52:42.732970Z","iopub.execute_input":"2025-12-01T02:52:42.733208Z","iopub.status.idle":"2025-12-01T02:52:51.947137Z","shell.execute_reply.started":"2025-12-01T02:52:42.733185Z","shell.execute_reply":"2025-12-01T02:52:51.946133Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preprocessing\nWe apply simple, consistent preprocessing for all models:\n\n- Drop high-missing or weak-features columns  \n- Impute `Age` and `Embarked`  \n- Label-encode categorical features  \n- Train/validation split with stratification\n","metadata":{}},{"cell_type":"code","source":"# Drop columns with high missingness or low signal for this demo\ndf = df.drop(columns=['Cabin','Name','Ticket'])\n\n# Basic imputations\ndf['Age'].fillna(df['Age'].median(), inplace=True)\ndf['Embarked'].fillna('S', inplace=True)\n\n# Encode categorical features\nfor col in ['Sex','Embarked']:\n    df[col] = LabelEncoder().fit_transform(df[col])\n\n# Features / target\nX = df.drop(columns=['PassengerId','Survived'])\ny = df['Survived']\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, stratify=y, random_state=42\n)\nX_train.shape, X_val.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:52:51.949101Z","iopub.execute_input":"2025-12-01T02:52:51.949391Z","iopub.status.idle":"2025-12-01T02:52:51.977480Z","shell.execute_reply.started":"2025-12-01T02:52:51.949367Z","shell.execute_reply":"2025-12-01T02:52:51.976510Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training & Benchmarking\n\nWe train each model, compute F1-score on the validation set, and record training time (seconds).\n","metadata":{}},{"cell_type":"code","source":"results = {}\n\n# LightGBM\nt0 = time.time()\nlgb_model = lgb.LGBMClassifier(random_state=42)\nlgb_model.fit(X_train, y_train)\npred = lgb_model.predict(X_val)\nresults['LightGBM'] = (f1_score(y_val, pred), time.time() - t0)\n\n# XGBoost\nt0 = time.time()\nxgb_model = xgb.XGBClassifier(\n    eval_metric='logloss',\n    random_state=42,\n    use_label_encoder=False\n)\nxgb_model.fit(X_train, y_train)\npred = xgb_model.predict(X_val)\nresults['XGBoost'] = (f1_score(y_val, pred), time.time() - t0)\n\n# CatBoost\nt0 = time.time()\ncb_model = CatBoostClassifier(verbose=0, random_state=42)\ncb_model.fit(X_train, y_train)\npred = cb_model.predict(X_val)\nresults['CatBoost'] = (f1_score(y_val, pred), time.time() - t0)\n\nresults\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:52:51.978645Z","iopub.execute_input":"2025-12-01T02:52:51.979197Z","iopub.status.idle":"2025-12-01T02:52:53.578020Z","shell.execute_reply.started":"2025-12-01T02:52:51.979170Z","shell.execute_reply":"2025-12-01T02:52:53.577313Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## F1-Score Comparison\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nmodels = list(results.keys())\nscores = [results[m][0] for m in models]\ntimes  = [results[m][1] for m in models]\n\nplt.figure(figsize=(6,4))\nplt.bar(models, scores)\nplt.title(\"F1-Score by Model\")\nplt.ylabel(\"F1-Score\")\nplt.ylim(0,1)\nplt.show()\n\nfor m in models:\n    print(f\"{m}: F1 = {results[m][0]:.3f} | Train time = {results[m][1]:.3f} s\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T02:52:53.578822Z","iopub.execute_input":"2025-12-01T02:52:53.579116Z","iopub.status.idle":"2025-12-01T02:52:53.794472Z","shell.execute_reply.started":"2025-12-01T02:52:53.579091Z","shell.execute_reply":"2025-12-01T02:52:53.793326Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclusion\n\nAll three boosting frameworks deliver strong performance on the Titanic dataset.\n\n**LightGBM**  \n- Very fast training time  \n- Strong F1-score  \n- Great choice when latency and scale matter  \n\n**XGBoost**  \n- Stable, widely adopted  \n- Rich ecosystem and documentation  \n\n**CatBoost**  \n- Handles categorical data very well  \n- Often competitive with minimal tuning  \n\nIn real projects, the final choice usually balances:\n- Performance (F1-score and other metrics)  \n- Training / inference time  \n- Implementation complexity  \n- Infrastructure constraints  \n\nThis benchmark provides a reproducible starting point for that decision.\n","metadata":{}}]}